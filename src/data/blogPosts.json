[
  {
    "id": 1,
    "title": "Understanding NLP Systems: From Preprocessing to RAG",
    "summary": "A comprehensive deep dive into the core components of modern Natural Language Processing. Learn how text is tokenized, embedded, attended to, and ultimately transformed into intelligent responses through models like RAG. Whether you're building a chatbot, search engine, or research tool‚Äîthis guide unpacks it all.",
    "date": "April 8, 2025",
    "imageUrl": "https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/Title.png",
    "slug": "Understanding-NLP-Systems",
    "tags": [
      "NLP",
      "AI",
      "Chatbot",
      "Transformers",
      "Text Embeddings",
      "RAG",
      "Attention Mechanism",
      "Language Models",
      "Information Retrieval",
      "Tutorial"
    ],
    "content": "<p>Natural Language Processing (NLP) has revolutionized the way machines understand and respond to human language. From powering intelligent assistants to helping researchers sift through vast amounts of text, NLP stands at the intersection of linguistics, data, and AI. In this blog, we&#39;ll unpack some of the most essential building blocks of NLP‚Äîfrom foundational preprocessing techniques to cutting-edge models like RAG. Whether you&#39;re a beginner or brushing up your skills, this guide will give you an in-depth understanding of how language is interpreted by machines.</p>\n<h2>Stemming and Lemmatization</h2>\n<p>One of the first steps in processing text is simplifying it. But simplification isn&#39;t just about removing words‚Äîit&#39;s about distilling them to their most meaningful forms.</p>\n<p><strong>Stemming</strong> is a rule-based process that chops off prefixes or suffixes to reduce words to their &quot;root&quot; form. However, these roots may not always be valid dictionary words. For instance, the word <code>flies</code> might be stemmed to <code>fli</code>, which isn&#39;t meaningful on its own but computationally efficient.<br><strong>Lemmatization</strong>, on the other hand, takes context into account and converts words into their <strong>base or dictionary form</strong>, preserving their grammatical meaning. So <code>flies</code> becomes <code>fly</code>, and <code>running</code> becomes <code>run</code>, both of which are valid.</p>\n<blockquote>\n<p>‚ö†Ô∏è <strong>Tip:</strong> Use stemming for high-speed, large-volume tasks, and lemmatization for tasks where accuracy matters more‚Äîlike sentiment analysis or chatbot response generation.</p>\n</blockquote>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/1.jpeg\" alt=\"Image 1\"><br>A side-by-side table of stemming vs lemmatization with input/output examples.</p>\n<h2>Tokenization: Breaking Language into Building Blocks</h2>\n<p>Before we can analyze text, we must <strong>split it into manageable pieces</strong>. Tokenization is the process of chopping text into units called tokens, which could be words, characters, or subwords.</p>\n<ul>\n<li><p><strong>Word Tokenization</strong> separates each word based on whitespace and punctuation.<br>  <em>Example:</em> &quot;I love Python.&quot; becomes [&quot;I&quot;, &quot;love&quot;, &quot;Python&quot;].</p>\n</li>\n<li><p><strong>Subword Tokenization</strong> is especially powerful for handling rare or unknown words. Instead of discarding unfamiliar words, it breaks them down into known sub-parts.<br>  <em>Example:</em> <code>unbelievable</code> ‚ûù [&quot;un&quot;, &quot;believ&quot;, &quot;able&quot;]</p>\n</li>\n</ul>\n<p>This granularity helps models generalize better, especially across different languages and technical terms.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/2.1.jpeg\" alt=\"image 2.1\"><br><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/2.2.jpeg\" alt=\"image 2.2\"><br><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/2.3.jpeg\" alt=\"image 2.3\"><br>Visual of tokenization types: sentence, word, subword, character.</p>\n<h2>Word Embeddings: Giving Numbers Meaning</h2>\n<p>Words need to be converted into numbers for a model to process them‚Äîbut not just any numbers. These vectors need to <strong>encode semantic meaning</strong>.</p>\n<p>Enter <strong>embeddings</strong>‚Äîdense vector representations of words. Words that appear in similar contexts end up with similar vectors. This enables models to understand relationships like:</p>\n<p>nginx</p>\n<p>CopyEdit</p>\n<p><code>king - man + woman ‚âà queen</code></p>\n<p>This vector math reveals how embeddings <strong>capture meaning, gender, context, and even analogies</strong>, all in high-dimensional space. These representations are learned using algorithms like Word2Vec, GloVe, or are directly baked into modern models like BERT.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/3.1.jpeg\" alt=\"image3.1\"><br><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/3.2.jpeg\" alt=\"image3.2\"><br>2D projection of word embeddings showing clusters (e.g., royal terms together, sports terms together).</p>\n<h2>Attention Mechanism: Mimicking Human Focus</h2>\n<p>When we read a sentence, we instinctively <strong>focus more on certain words</strong> depending on context. The <strong>attention mechanism</strong> brings this human-like prioritization to machine learning.</p>\n<p>It works by <strong>assigning importance weights</strong> to different words in the input based on their relevance to each other. For instance, in the sentence &quot;The cat is jumping high,&quot; attention might focus more on &quot;cat&quot; and &quot;jumping&quot; than on &quot;the&quot; or &quot;is&quot;.</p>\n<p>This mechanism powers many breakthroughs in NLP because it allows models to dynamically emphasize important parts of the input.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/4.1.jpeg\" alt=\"image4.1\"><br><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/4.2.jpeg\" alt=\"image4.2\"><br><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/4.3.jpeg\" alt=\"image4.3\"><br>A heatmap showing attention weights across words in a sentence.</p>\n<h2>Transformers: The Brains Behind Modern NLP</h2>\n<p>Before transformers, models processed words <strong>sequentially</strong>, which made understanding long-term dependencies hard. Transformers <strong>look at the entire sentence at once</strong>, analyzing relationships between every word pair.</p>\n<p>Here&#39;s how they work:</p>\n<ol>\n<li><p><strong>Embeddings + Positional Encoding</strong>: Each word is turned into a vector and tagged with its position.</p>\n</li>\n<li><p><strong>Attention Layers</strong>: The model figures out which words are most important to each other.</p>\n</li>\n<li><p><strong>Feed-forward Layers</strong>: These layers refine the understanding at deeper levels.</p>\n</li>\n</ol>\n<p>This parallel architecture is what powers today&#39;s NLP superstars like BERT, GPT, and T5. It&#39;s <strong>fast, context-aware</strong>, and scales beautifully.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/5.jpeg\" alt=\"image5\"><br>Diagram of transformer architecture with embedding, attention, and output layers.</p>\n<h2>Measuring Text Similarity</h2>\n<p>Understanding how similar two pieces of text are is crucial for applications like duplicate detection, question-answering, or recommendations. Several metrics help with this:</p>\n<ul>\n<li><p><strong>Cosine Similarity</strong> looks at the angle between word vectors. A smaller angle (closer to 1) means higher similarity.</p>\n</li>\n<li><p><strong>Jaccard Similarity</strong> compares how many common words two sentences have vs. how many total unique words they contain.</p>\n</li>\n<li><p><strong>Euclidean Distance</strong> measures how far apart the vectors are in space‚Äîcloser means more similar.</p>\n</li>\n</ul>\n<p>Each has its use cases, but cosine similarity tends to dominate in NLP tasks involving embeddings.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/6.jpeg\" alt=\"image6\"><br>Geometric visualization comparing cosine similarity and Euclidean distance.</p>\n<h2>Information Retrieval: Finding What Matters</h2>\n<p>Search engines, chatbots, and document scanners rely on <strong>information retrieval</strong> to locate the most relevant content.</p>\n<p>It involves:</p>\n<ol>\n<li><p><strong>Document Representation</strong>: Turning large amounts of unstructured text into searchable form.</p>\n</li>\n<li><p><strong>Scoring &amp; Ranking</strong>: Calculating relevance between query and documents.</p>\n</li>\n<li><p><strong>Indexing</strong>: Like a book index, this allows fast lookup instead of reading everything.</p>\n</li>\n</ol>\n<blockquote>\n<p>üß† <strong>Tip:</strong> Strong retrieval = faster, more accurate results.</p>\n</blockquote>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/7.jpeg\" alt=\"image7\"><br>Diagram of IR pipeline: query ‚ûù document store ‚ûù ranked results.</p>\n<h2>Retrieval Models in RAG (Retrieval-Augmented Generation)</h2>\n<p><strong>RAG</strong> combines the power of two models:</p>\n<ul>\n<li><p>A <strong>retriever</strong> that fetches relevant documents based on the query</p>\n</li>\n<li><p>A <strong>generator</strong> that crafts a human-like response based on those documents</p>\n</li>\n</ul>\n<h3>Traditional Retrieval Models</h3>\n<ul>\n<li><p><strong>TF-IDF</strong> gives higher importance to rare but significant terms.</p>\n</li>\n<li><p><strong>BM25</strong> builds on TF-IDF with tuning for document length and term saturation.</p>\n</li>\n</ul>\n<blockquote>\n<p>Example: The term &quot;warming&quot; might be common in a climate document set, but it&#39;ll get higher relevance when paired with unique query contexts.</p>\n</blockquote>\n<h3>Dense Retrieval</h3>\n<p>Dense models like <strong>DPR (Dense Passage Retrieval)</strong> learn to map questions and answers into the same vector space using embeddings. Even if the words differ, they can still match on meaning.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/8.jpeg\" alt=\"image8\"><br>Dual-encoder DPR architecture: one for query, one for documents.</p>\n<h2>Generative Models: Crafting Human-like Answers</h2>\n<p>Once information is retrieved, <strong>generative models</strong> like GPT step in. They don&#39;t just copy‚Äîthey create. Given retrieved documents and a prompt, they generate <strong>fluent, coherent, and informative responses</strong>.</p>\n<ul>\n<li><p><strong>Coherence</strong> ensures every sentence fits logically</p>\n</li>\n<li><p><strong>Completeness</strong> guarantees all angles are covered</p>\n</li>\n<li><p><strong>Adaptability</strong> lets the model personalize responses to context</p>\n</li>\n</ul>\n<p>This phase is crucial in making responses sound natural and complete.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/9.jpeg\" alt=\"image9\"><br>Flow of generation from prompt to context to final answer.</p>\n<h2>RAG Pipeline: Factual, Fast, and Fluent</h2>\n<p>Putting it all together:</p>\n<ol>\n<li><p><strong>User Query</strong>: &quot;What are the benefits of meditation?&quot;</p>\n</li>\n<li><p><strong>Retriever</strong>: Finds documents discussing mental health, focus, and relaxation.</p>\n</li>\n<li><p><strong>Scoring</strong>: Ranks documents based on semantic similarity.</p>\n</li>\n<li><p><strong>Generator</strong>: Produces a natural-sounding summary of the key points.</p>\n</li>\n<li><p><strong>Final Output</strong>: &quot;Meditation improves focus, reduces stress, and enhances emotional well-being.&quot;</p>\n</li>\n</ol>\n<p>This combination ensures not only relevance but also <strong>depth and clarity</strong>‚Äîideal for research, customer support, and education.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-5/10.jpeg\" alt=\"image10\"><br>Full RAG workflow chart with arrows from input ‚ûù retrieval ‚ûù ranking ‚ûù generation ‚ûù output.</p>\n",
    "targetAudience": [
      "Data Scientists",
      "AI Engineers",
      "ML Enthusiasts",
      "Technical Writers",
      "Chatbot Developers"
    ]
  },
  {
    "id": 1,
    "title": "Blog Automation Workflow for Gen-Z Creators",
    "summary": "Time-Saving: Automate repetitive tasks like content generation and distribution.",
    "date": "March 29, 2025",
    "imageUrl": "https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/First-blog/WhatsApp+Image+2025-03-29+at+9.14.21+AM.jpeg",
    "slug": "custom-ai-workflows",
    "tags": [
      "Automation",
      "AI",
      "Content Creation",
      "Workflow",
      "n8n",
      "OpenAI",
      "Productivity",
      "Gen-Z",
      "No-Code",
      "Integration"
    ],
    "content": "<h1>Blog Automation Workflow for Gen-Z Creators</h1>\n<h2>Why This Workflow?</h2>\n<ul>\n<li><strong>Time-Saving</strong>: Automate repetitive tasks like content generation and distribution.</li>\n<li><strong>Multi-Platform Ready</strong>: Share content on Slack, Notion, email, and social media.</li>\n<li><strong>AI-Powered</strong>: Use OpenAI to brainstorm and write blogs in minutes.</li>\n<li><strong>Perfect for Beginners</strong>: No coding skills needed‚Äîjust set up and go!</li>\n</ul>\n<h2>Step-by-Step Process</h2>\n<h3>1. Start with Google Sheets</h3>\n<p><strong>What it does</strong>: Triggers the workflow when you add a new blog idea to your Google Sheets.<br><strong>How does it work:</strong></p>\n<p>Here I have given the input as this:</p>\n<table>\n<thead>\n<tr>\n<th>Id</th>\n<th>Title</th>\n<th>Subtitle</th>\n<th>Subject</th>\n<th>Keywords</th>\n<th>Tags</th>\n<th>Tone</th>\n<th>Image</th>\n<th>Target_Audience</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Sample Title</td>\n<td>Sample Subtitle</td>\n<td>Tech</td>\n<td>AI, Automation</td>\n<td>Tech, Blog</td>\n<td>Informative</td>\n<td>Image1.jpg</td>\n<td>Gen-Z Creators</td>\n</tr>\n</tbody></table>\n<p>Taking this as input, our custom AI agent can trigger with the message we write in the next section. To connect Google Sheets, follow the <a href=\"https://docs.n8n.io/external-secrets/#use-secrets-in-n8n-credentials\">n8n Google Sheets setup guide</a>.</p>\n<h3>2. Generate Content with OpenAI</h3>\n<p><strong>What it does</strong>: Uses AI to write a full blog post from your topic and keywords.<br><strong>How does this work:</strong></p>\n<p>In this step, we must follow OpenAI&#39;s guidelines to create API keys for connecting our n8n workflow with ChatGPT.</p>\n<p>Refer to these resources for guidance:</p>\n<ul>\n<li><a href=\"https://platform.openai.com/docs/api-reference/introduction\">OpenAI API setup</a></li>\n<li><a href=\"https://docs.n8n.io/integrations/builtin/credentials/openai/\">n8n OpenAI integration</a></li>\n</ul>\n<p>In order to get the best output, refer to this sample image that illustrates how the content is structured:</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/First-blog/image.jpeg\" alt=\"Prompt Example\"></p>\n<h3>3. Edit Your Content</h3>\n<p><strong>What it does</strong>: Lets you tweak the AI&#39;s draft to match your voice.<br><strong>Example</strong>: Change formal phrases like <em>&quot;One may consider&quot;</em> to <em>&quot;You should totally try...&quot;</em><br><strong>Why are we using this</strong>: Because ChatGPT may hallucinate or provide inaccurate information, so this editing step ensures high-quality content.</p>\n<h3>4. Split Content for Sharing</h3>\n<p><strong>What it does</strong>: Breaks your blog into bite-sized pieces for social media, emails, etc.<br><strong>How and Why are we doing this:</strong> Content is divided for both <strong>Slack</strong> and <strong>Notion</strong> to streamline distribution.</p>\n<h3>5. Notify Your Team on Slack</h3>\n<p><strong>What it does</strong>: Sends a Slack message when the blog is ready.<br><strong>How can we achieve this:</strong> Follow the <a href=\"https://docs.n8n.io/integrations/builtin/credentials/slack/\">Slack setup guide</a> for steps to create a channel, app, OAuth ID, and scopes to connect Slack with n8n.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/First-blog/Slack.jpeg\" alt=\"Slack Example\"></p>\n<h3>6. Organize in Notion</h3>\n<p><strong>What it does</strong>: Saves your blog details (title, tags, publish date) in a Notion database.<br><strong>How does this work:</strong> Follow this <a href=\"https://docs.n8n.io/integrations/builtin/credentials/notion/\">Notion setup guide</a> to connect your Notion workspace with n8n.</p>\n<h3>7. Add Custom Magic with Code</h3>\n<p><strong>What it does</strong>: Runs scripts for advanced tasks.<br><strong>How does this help:</strong> Upon success, this step triggers a status code <code>200</code> to confirm completion and sends an email to subscribers. It also uses an OpenAI agent to notify that new content is available with a link for readers. Follow Steps 1 and 2 to set this up.</p>\n<h3>8. Email Your Subscribers</h3>\n<p><strong>What it does</strong>: Sends personalized emails to your audience.<br><strong>How does this work:</strong> Like Google Sheets integration, add a Gmail node in n8n and configure your account for email automation.</p>\n<p>Now our workflow is ready to send content models.</p>\n<h2>Full Workflow in Action üéÆ</h2>\n<ol>\n<li>Add a blog idea to <strong>Google Sheets</strong> ‚Üí triggers the workflow.</li>\n<li><strong>OpenAI</strong> writes the draft ‚Üí you edit it.</li>\n<li><strong>Split</strong> the content into social posts, emails, etc.</li>\n<li>Get team feedback via <strong>Slack</strong>.</li>\n<li>Log the blog in <strong>Notion</strong>.</li>\n<li>Use <strong>Code</strong> for extra automation.</li>\n<li>Send the final piece to subscribers via <strong>Gmail</strong>.</li>\n</ol>\n<h2>Why You&#39;ll Love It</h2>\n<ul>\n<li><strong>Effortless</strong>: Focus on creativity while AI handles the heavy lifting.</li>\n<li><strong>Scalable</strong>: Go from 1 blog/month to 10 blogs/week.</li>\n<li><strong>Trendy</strong>: Perfect for Gen-Z creators who love tech and side hustles.</li>\n</ul>\n",
    "targetAudience": [
      "Content Creators",
      "Gen-Z",
      "Bloggers"
    ]
  },
  {
    "id": 2,
    "title": "Creating RAG AI-Agent Chat Bot for Your Website: Part 1",
    "summary": "Seemsless integration of RAG model with your chatbot and decrease the work of interviewing many people where they can just ask questions about you directly here. Click here to see more",
    "date": "April 1, 2025",
    "imageUrl": "https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Blog+2+-part+1/figure+1.jpeg",
    "slug": "rag-ai-agent-chat-bot-part-1",
    "tags": [
      "RAG",
      "AI",
      "Chatbot",
      "Backend",
      "n8n",
      "OpenAI",
      "Supabase",
      "Vector Database",
      "API Integration",
      "Tutorial"
    ],
    "content": "<h1>Creating RAG AI-Agent Chat Bot for Your Website: Part 1</h1>\n<h2>What you can expect</h2>\n<p>Seemsless integration of RAG model with your chatbot and decrease the work of interviewing many people where they can just ask questions about you directly here. Click here to see more</p>\n<h2>Introduction</h2>\n<p>This guide will walk you through creating a RAG (Retrieval-Augmented Generation) AI-Agent Chat Bot for your website. We&#39;ll use n8n for workflow automation, OpenAI for AI processing, and Supabase for vector storage. This implementation is split into two parts:</p>\n<ul>\n<li>Part 1 (Current): Backend setup and workflow configuration</li>\n<li>Part 2: Frontend integration and deployment</li>\n</ul>\n<h2>Prerequisites</h2>\n<p>Before we begin, ensure you have:</p>\n<ol>\n<li>Your own website with chatbot features</li>\n<li>N8N cloud version (latest)</li>\n<li>Chat-gpt API access with:<ul>\n<li>GPT-3.5-turbo model access</li>\n<li>text-embedding-ada-002 model access</li>\n</ul>\n</li>\n<li>Supabase account with:<ul>\n<li>Vector storage enabled</li>\n<li>PostgreSQL database</li>\n</ul>\n</li>\n<li>Google Drive access (for document storage)</li>\n<li>Basic understanding of:<ul>\n<li>API integrations</li>\n<li>Vector databases</li>\n<li>Webhook configurations</li>\n</ul>\n</li>\n</ol>\n<h2>Required Environment Variables</h2>\n<p>Set up these environment variables in your n8n instance:</p>\n<pre><code class=\"language-env\">OPENAI_API_KEY=your_openai_api_key\nSUPABASE_URL=your_supabase_url\nSUPABASE_KEY=your_supabase_key\nGOOGLE_DRIVE_CREDENTIALS=your_google_drive_credentials\n</code></pre>\n<h2>Step-by-Step Implementation</h2>\n<h3>Step 1: Initial Workflow Setup</h3>\n<h4>Testing with Chat Node</h4>\n<p>First, we&#39;ll build a workflow with Chat Node for testing without webhook integration.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Blog+2+-part+1/figure+2.jpeg\" alt=\"Chat Connected to RAG Agent\"><br><em>Figure 2: Chat Connected to RAG Agent</em></p>\n<h3>Step 2: Data Vectorization Workflow</h3>\n<h4>Creating Vector Storage</h4>\n<p>We&#39;ll create a new workflow to convert our data to vectors using Supabase Vector Storage.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Blog+2+-part+1/figure+3.jpeg\" alt=\"Converting Data to Vector and Needed Workflow\"><br><em>Figure 3: Converting Data to Vector and Needed Workflow</em></p>\n<h4>Workflow Configuration Steps</h4>\n<ol>\n<li><p><strong>Trigger Setup</strong></p>\n<ul>\n<li>Node: <code>When clicking &#39;Test workflow&#39;</code></li>\n<li>Connect to: <code>Google Drive (download file)</code></li>\n</ul>\n</li>\n<li><p><strong>File Download</strong></p>\n<ul>\n<li>Node: <code>Google Drive (download file)</code></li>\n<li>Connect to: <code>Default Data Loader</code></li>\n</ul>\n</li>\n<li><p><strong>Data Loading</strong></p>\n<ul>\n<li>Node: <code>Default Data Loader</code></li>\n<li>Connect to: <code>Recursive Character Text Splitter</code></li>\n</ul>\n</li>\n<li><p><strong>Text Chunking</strong></p>\n<ul>\n<li>Node: <code>Recursive Character Text Splitter</code></li>\n<li>Connect to: <code>Embeddings OpenAI</code></li>\n</ul>\n</li>\n<li><p><strong>Embedding Generation</strong></p>\n<ul>\n<li>Node: <code>Embeddings OpenAI</code></li>\n<li>Configuration:<ul>\n<li>Use OpenAI API key</li>\n<li>Choose text-embedding-ada-002 model</li>\n</ul>\n</li>\n<li>Connect to: <code>Supabase Vector Store</code></li>\n</ul>\n</li>\n<li><p><strong>Vector Storage</strong></p>\n<ul>\n<li>Node: <code>Supabase Vector Store</code></li>\n<li>Configuration:<ul>\n<li>Use Supabase credentials for vector storage</li>\n<li>Store embeddings in dedicated table</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h3>Step 3: Chat Response Workflow</h3>\n<h4>1. Chat Trigger Setup</h4>\n<ul>\n<li>Node: Chat window</li>\n<li>Purpose: Endpoint for chatbot queries</li>\n<li>Configuration:<ul>\n<li>Method: <code>POST</code></li>\n<li>Response: <code>Return Data</code></li>\n<li>Connect to: <code>AI Agent</code></li>\n</ul>\n</li>\n</ul>\n<h4>2. Context Retrieval</h4>\n<ul>\n<li>Node: <code>Supabase Vector Store (Search)</code></li>\n<li>Purpose: Fetch relevant document chunks</li>\n<li>Configuration:<ul>\n<li>Use Supabase credentials</li>\n<li>Query embeddings based on user input</li>\n</ul>\n</li>\n<li>Connect to: <code>AI Agent</code></li>\n</ul>\n<h4>3. AI Agent Configuration</h4>\n<ul>\n<li>Node: <code>AI Agent</code></li>\n<li>Purpose: Process queries and context</li>\n<li>Configuration:<ul>\n<li>Chat Model: <code>OpenAI GPT</code></li>\n<li>Memory: <code>PostgreSQL Chat Memory</code></li>\n<li>Context Input: <code>Supabase Vector Store (Search) Output</code></li>\n</ul>\n</li>\n<li>Connect to: <code>OpenAI Chat Model</code></li>\n</ul>\n<h4>4. Response Generation</h4>\n<ul>\n<li>Node: <code>OpenAI Chat Model</code></li>\n<li>Purpose: Generate AI responses</li>\n<li>Configuration:<ul>\n<li>Use OpenAI API Key</li>\n<li>Response Format: <code>Text</code></li>\n</ul>\n</li>\n<li>Connect to: <code>Postgres Chat Memory</code> and <code>Webhook (Response)</code></li>\n</ul>\n<h4>5. Chat History Storage</h4>\n<ul>\n<li>Node: <code>Postgres Chat Memory</code></li>\n<li>Purpose: Store conversation history</li>\n<li>Configuration:<ul>\n<li>Use same database as vector storage</li>\n<li>Log messages by user ID</li>\n</ul>\n</li>\n<li>Connect to: <code>AI Agent</code></li>\n</ul>\n<h3>Step 4: Webhook Integration</h3>\n<h4>Replacing Chat Node with Webhook</h4>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Blog+2+-part+1/figure+4.jpeg\" alt=\"Webhook Node Configuration\"><br><em>Figure 4: Webhook Node Configuration</em></p>\n<h4>CORS Configuration</h4>\n<p>Configure origins (CORS) for proper access.</p>\n<h3>Step 5: Testing with Postman</h3>\n<h4>Headers Configuration</h4>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Blog+2+-part+1/figure+5.jpeg\" alt=\"Required Headers in Postman\"><br><em>Figure 5: Required Headers in Postman</em></p>\n<h4>Request Body Setup</h4>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Blog+2+-part+1/figure+6.jpeg\" alt=\"Request Body Configuration\"><br><em>Figure 6: Request Body Configuration</em></p>\n<h4>Testing Process</h4>\n<ol>\n<li>Copy webhook test URL</li>\n<li>Paste in Postman</li>\n<li>Start listening for test events</li>\n<li>Send request</li>\n<li>Verify response</li>\n</ol>\n<h3>Step 6: Field Node Integration</h3>\n<h4>Adding Field Nodes</h4>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Blog+2+-part+1/figure+7.png\" alt=\"AI-Agent Node with Field Nodes\"><br><em>Figure 7: AI-Agent Node with Field Nodes</em></p>\n<h4>System Message Configuration</h4>\n<p>Add system message in AI agent options to define behavior.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Blog+2+-part+1/figure+8.jpeg\" alt=\"AI-agent with system message\"><br><em>Figure 8: AI-agent with system message</em></p>\n<h3>Step 7: Production Testing</h3>\n<h4>Final Testing</h4>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Blog+2+-part+1/figure+9.jpeg\" alt=\"Production URL Testing Results\"><br><em>Figure 9: Production URL Testing Results</em></p>\n<h2>Troubleshooting</h2>\n<h3>Common Issues</h3>\n<ol>\n<li><p><strong>CORS Errors</strong></p>\n<ul>\n<li>Ensure CORS is properly configured in webhook node</li>\n<li>Check allowed origins in n8n settings</li>\n</ul>\n</li>\n<li><p><strong>API Rate Limits</strong></p>\n<ul>\n<li>Monitor OpenAI API usage</li>\n<li>Implement rate limiting if needed</li>\n</ul>\n</li>\n<li><p><strong>Vector Search Issues</strong></p>\n<ul>\n<li>Verify Supabase connection</li>\n<li>Check embedding dimensions match</li>\n</ul>\n</li>\n<li><p><strong>Webhook Failures</strong></p>\n<ul>\n<li>Validate webhook URL</li>\n<li>Check request/response format</li>\n</ul>\n</li>\n</ol>\n<h3>Debugging Tips</h3>\n<ol>\n<li>Use n8n execution logs</li>\n<li>Monitor network requests in browser</li>\n<li>Check Supabase logs</li>\n<li>Verify API responses in Postman</li>\n</ol>\n<h2>Security Considerations</h2>\n<ol>\n<li>Never expose API keys in client-side code</li>\n<li>Implement proper authentication</li>\n<li>Use environment variables for sensitive data</li>\n<li>Regular security audits of webhook endpoints</li>\n<li>Monitor API usage and implement rate limiting</li>\n</ol>\n<h2>Performance Optimization</h2>\n<ol>\n<li>Optimize chunk sizes for better retrieval</li>\n<li>Implement caching where appropriate</li>\n<li>Monitor database query performance</li>\n<li>Use appropriate embedding models</li>\n<li>Implement proper error handling</li>\n</ol>\n<h2>Next Steps</h2>\n<p>To connect this to your website&#39;s chat-bot backend, please refer to Part 2 of this guide.</p>\n",
    "targetAudience": [
      "Developers",
      "AI Enthusiasts",
      "Website Owners"
    ]
  },
  {
    "id": 3,
    "title": "Creating RAG AI-Agent Chat Bot for your website Part 2",
    "summary": "A professional portfolio website with an AI-powered chatbot that can answer questions about your work, skills, and experience.",
    "date": "April 1, 2025",
    "imageUrl": "https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/First+Full.jpeg",
    "slug": "rag-ai-agent-chat-bot-part-2",
    "tags": [
      "RAG",
      "AI",
      "Chatbot",
      "Frontend",
      "React",
      "TypeScript",
      "API Integration",
      "Error Handling",
      "Performance",
      "Tutorial"
    ],
    "content": "<h1>Creating RAG AI-Agent Chat Bot for your website Part 2</h1>\n<h2>üéØ What You&#39;ll Build</h2>\n<p>A professional portfolio website with an AI-powered chatbot that can answer questions about your work, skills, and experience.</p>\n<h2>üöÄ Quick Start</h2>\n<ol>\n<li>Set up your n8n workflow (Part 1)</li>\n<li>Configure your frontend (Part 2)</li>\n<li>Test and deploy</li>\n</ol>\n<h2>üìã Prerequisites</h2>\n<ul>\n<li>Basic knowledge of React and TypeScript</li>\n<li>An n8n workflow (from Part 1)</li>\n<li>Your portfolio website code</li>\n</ul>\n<h2>üõ†Ô∏è Step-by-Step Implementation</h2>\n<h3>1. Setting Up Your Environment</h3>\n<h4>1.1 Configure Environment Variables</h4>\n<p>Create a <code>.env</code> file in your project root:</p>\n<pre><code class=\"language-env\">VITE_WEBHOOK_URL=your-n8n-production-webhook-url\n</code></pre>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Github+Api.jpeg\" alt=\"GitHub Secrets Configuration for Webhook URL\"><br><em>Figure 2: GitHub Secrets Configuration for Webhook URL</em></p>\n<h4>1.2 Set Up GitHub Secrets</h4>\n<ol>\n<li>Go to your repository settings</li>\n<li>Navigate to Secrets and Variables ‚Üí Actions</li>\n<li>Add <code>VITE_WEBHOOK_URL</code> with your n8n webhook URL</li>\n</ol>\n<h3>2. Building the Chat API Service</h3>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Chatwindow.jpeg\" alt=\"Chat windows in website\"><br><em>Figure 3: Chat windows in website</em></p>\n<h4>2.1 Create the API Service</h4>\n<p>Create <code>src/utils/chatApi.ts</code>:</p>\n<pre><code class=\"language-typescript\">interface MessageType {\n  id: string;\n  content: string;\n  sender: &#39;user&#39; | &#39;bot&#39;;\n  timestamp: string;\n}\n\ninterface ApiResponse {\n  response?: string;\n  message?: string;\n  status?: string;\n  timestamp?: number;\n}\n\nconst API_BASE_URL = import.meta.env.VITE_WEBHOOK_URL;\n\n// Validate API response\nconst isValidResponse = (data: any): data is ApiResponse =&gt; {\n  return &#39;response&#39; in data || &#39;message&#39; in data;\n};\n\nexport const sendMessage = async (message: string): Promise&lt;MessageType&gt; =&gt; {\n  try {\n    const response = await fetch(API_BASE_URL, {\n      method: &#39;POST&#39;,\n      headers: {\n        &#39;Content-Type&#39;: &#39;application/json&#39;,\n        &#39;Accept&#39;: &#39;application/json&#39;,\n      },\n      body: JSON.stringify({\n        message,\n        timestamp: Date.now(),\n        source: &#39;portfolio-chat&#39;\n      }),\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.status}`);\n    }\n\n    const data = await response.json();\n    \n    if (!isValidResponse(data)) {\n      throw new Error(&#39;Invalid response format&#39;);\n    }\n\n    return {\n      id: Date.now().toString(),\n      content: data.response || data.message || &quot;I couldn&#39;t process that message.&quot;,\n      sender: &#39;bot&#39;,\n      timestamp: new Date().toISOString()\n    };\n  } catch (error) {\n    console.error(&#39;Failed to send message:&#39;, error);\n    return {\n      id: Date.now().toString(),\n      content: &quot;Sorry, I&#39;m having trouble connecting right now. Please try again later.&quot;,\n      sender: &#39;bot&#39;,\n      timestamp: new Date().toISOString(),\n    };\n  }\n};\n</code></pre>\n<h4>2.2 Create a Chat Component</h4>\n<p>Create <code>src/components/Chat.tsx</code>:</p>\n<pre><code class=\"language-typescript\">import React, { useState, useRef, useEffect } from &#39;react&#39;;\nimport { sendMessage } from &#39;../utils/chatApi&#39;;\n\ninterface ChatMessage {\n  id: string;\n  content: string;\n  sender: &#39;user&#39; | &#39;bot&#39;;\n  timestamp: string;\n}\n\nexport const Chat: React.FC = () =&gt; {\n  const [messages, setMessages] = useState&lt;ChatMessage[]&gt;([]);\n  const [input, setInput] = useState(&#39;&#39;);\n  const [isLoading, setIsLoading] = useState(false);\n  const messagesEndRef = useRef&lt;HTMLDivElement&gt;(null);\n\n  const scrollToBottom = () =&gt; {\n    messagesEndRef.current?.scrollIntoView({ behavior: &#39;smooth&#39; });\n  };\n\n  useEffect(() =&gt; {\n    scrollToBottom();\n  }, [messages]);\n\n  const handleSubmit = async (e: React.FormEvent) =&gt; {\n    e.preventDefault();\n    if (!input.trim() || isLoading) return;\n\n    const userMessage: ChatMessage = {\n      id: Date.now().toString(),\n      content: input,\n      sender: &#39;user&#39;,\n      timestamp: new Date().toISOString(),\n    };\n\n    setMessages(prev =&gt; [...prev, userMessage]);\n    setInput(&#39;&#39;);\n    setIsLoading(true);\n\n    try {\n      const response = await sendMessage(input);\n      setMessages(prev =&gt; [...prev, response]);\n    } catch (error) {\n      console.error(&#39;Error sending message:&#39;, error);\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  return (\n    &lt;div className=&quot;flex flex-col h-[500px] w-full max-w-2xl mx-auto&quot;&gt;\n      &lt;div className=&quot;flex-1 overflow-y-auto p-4 space-y-4&quot;&gt;\n        {messages.map((message) =&gt; (\n          &lt;div\n            key={message.id}\n            className={`flex ${\n              message.sender === &#39;user&#39; ? &#39;justify-end&#39; : &#39;justify-start&#39;\n            }`}\n          &gt;\n            &lt;div\n              className={`max-w-[80%] rounded-lg p-3 ${\n                message.sender === &#39;user&#39;\n                  ? &#39;bg-blue-500 text-white&#39;\n                  : &#39;bg-gray-200 text-gray-800&#39;\n              }`}\n            &gt;\n              {message.content}\n            &lt;/div&gt;\n          &lt;/div&gt;\n        ))}\n        {isLoading &amp;&amp; (\n          &lt;div className=&quot;flex justify-start&quot;&gt;\n            &lt;div className=&quot;bg-gray-200 rounded-lg p-3&quot;&gt;\n              &lt;div className=&quot;flex space-x-2&quot;&gt;\n                &lt;div className=&quot;w-2 h-2 bg-gray-500 rounded-full animate-bounce&quot; /&gt;\n                &lt;div className=&quot;w-2 h-2 bg-gray-500 rounded-full animate-bounce delay-100&quot; /&gt;\n                &lt;div className=&quot;w-2 h-2 bg-gray-500 rounded-full animate-bounce delay-200&quot; /&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n          &lt;/div&gt;\n        )}\n        &lt;div ref={messagesEndRef} /&gt;\n      &lt;/div&gt;\n      &lt;form onSubmit={handleSubmit} className=&quot;p-4 border-t&quot;&gt;\n        &lt;div className=&quot;flex space-x-2&quot;&gt;\n          &lt;input\n            type=&quot;text&quot;\n            value={input}\n            onChange={(e) =&gt; setInput(e.target.value)}\n            placeholder=&quot;Type your message...&quot;\n            className=&quot;flex-1 p-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500&quot;\n            disabled={isLoading}\n          /&gt;\n          &lt;button\n            type=&quot;submit&quot;\n            disabled={isLoading}\n            className=&quot;px-4 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:opacity-50&quot;\n          &gt;\n            Send\n          &lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/form&gt;\n    &lt;/div&gt;\n  );\n};\n</code></pre>\n<h4>2.3 Add Chat to Your Portfolio</h4>\n<p>Update <code>src/App.tsx</code>:</p>\n<pre><code class=\"language-typescript\">import { Chat } from &#39;./components/Chat&#39;;\n\nfunction App() {\n  return (\n    &lt;div className=&quot;min-h-screen bg-gray-50&quot;&gt;\n      {/* Your existing portfolio content */}\n      &lt;section className=&quot;py-12 bg-white&quot;&gt;\n        &lt;div className=&quot;container mx-auto px-4&quot;&gt;\n          &lt;h2 className=&quot;text-3xl font-bold text-center mb-8&quot;&gt;\n            Chat with Me\n          &lt;/h2&gt;\n          &lt;Chat /&gt;\n        &lt;/div&gt;\n      &lt;/section&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre>\n<h3>3. Testing Your Setup</h3>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Postman.jpeg\" alt=\"Testing API Endpoint with Postman\"><br><em>Figure 4: Testing API Endpoint with Postman</em></p>\n<h4>3.1 Test the API Connection</h4>\n<pre><code class=\"language-bash\">curl -X POST \\\n  -H &quot;Content-Type: application/json&quot; \\\n  -d &#39;{&quot;message&quot;:&quot;test message&quot;}&#39; \\\n  your-n8n-production-webhook-url\n</code></pre>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/Blog-2/Browser+Testing.jpeg\" alt=\"Browser testing\"><br><em>Figure 5: Browser testing</em></p>\n<h4>3.2 Check Browser Console</h4>\n<ul>\n<li>Open Developer Tools (F12)</li>\n<li>Look for:<ul>\n<li>Successful API requests</li>\n<li>Response data</li>\n<li>Any error messages</li>\n</ul>\n</li>\n</ul>\n<h3>4. Common Issues &amp; Solutions</h3>\n<h4>4.1 CORS Issues</h4>\n<p>If you see CORS errors, ensure your n8n workflow includes these headers:</p>\n<pre><code class=\"language-typescript\">&#39;Access-Control-Allow-Origin&#39;: &#39;*&#39;\n&#39;Access-Control-Allow-Methods&#39;: &#39;POST, GET, OPTIONS&#39;\n&#39;Access-Control-Allow-Headers&#39;: &#39;Content-Type&#39;\n</code></pre>\n<h4>4.2 Connection Problems</h4>\n<ul>\n<li>Verify your webhook URL is correct</li>\n<li>Check if n8n workflow is active</li>\n<li>Ensure environment variables are set</li>\n</ul>\n<h3>5. Best Practices</h3>\n<h4>5.1 Error Handling</h4>\n<pre><code class=\"language-typescript\">// Custom error types\nclass ApiError extends Error {\n  constructor(\n    message: string,\n    public status?: number,\n    public data?: any\n  ) {\n    super(message);\n    this.name = &#39;ApiError&#39;;\n  }\n}\n\n// Enhanced error handling\nconst handleApiError = (error: unknown): string =&gt; {\n  if (error instanceof ApiError) {\n    switch (error.status) {\n      case 404:\n        return &quot;The requested resource wasn&#39;t found.&quot;;\n      case 403:\n        return &quot;You don&#39;t have permission to access this resource.&quot;;\n      case 500:\n        return &quot;The server encountered an error. Please try again later.&quot;;\n      default:\n        return &quot;An unexpected error occurred. Please try again.&quot;;\n    }\n  }\n  return &quot;An unexpected error occurred. Please try again.&quot;;\n};\n</code></pre>\n<h4>5.2 Rate Limiting Implementation</h4>\n<pre><code class=\"language-typescript\">// src/utils/rateLimiter.ts\nclass RateLimiter {\n  private requests: number[] = [];\n  private readonly limit: number;\n  private readonly window: number;\n\n  constructor(limit: number = 10, windowMs: number = 60000) {\n    this.limit = limit;\n    this.window = windowMs;\n  }\n\n  canMakeRequest(): boolean {\n    const now = Date.now();\n    this.requests = this.requests.filter(\n      time =&gt; now - time &lt; this.window\n    );\n\n    if (this.requests.length &gt;= this.limit) {\n      return false;\n    }\n\n    this.requests.push(now);\n    return true;\n  }\n}\n\n// Usage in chatApi.ts\nconst rateLimiter = new RateLimiter(10, 60000); // 10 requests per minute\n\nexport const sendMessage = async (message: string): Promise&lt;MessageType&gt; =&gt; {\n  if (!rateLimiter.canMakeRequest()) {\n    throw new ApiError(&#39;Rate limit exceeded. Please try again later.&#39;);\n  }\n  // ... rest of the sendMessage implementation\n};\n</code></pre>\n<h2>üîç Troubleshooting Guide</h2>\n<h3>Common Errors</h3>\n<table>\n<thead>\n<tr>\n<th>Error Code</th>\n<th>Meaning</th>\n<th>Solution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>404</td>\n<td>Wrong API endpoint</td>\n<td>Check your webhook URL</td>\n</tr>\n<tr>\n<td>403</td>\n<td>CORS issue</td>\n<td>Add CORS headers</td>\n</tr>\n<tr>\n<td>500</td>\n<td>Server error</td>\n<td>Check n8n workflow</td>\n</tr>\n</tbody></table>\n<h3>Debugging Steps</h3>\n<ol>\n<li>Check Network tab in DevTools</li>\n<li>Verify environment variables</li>\n<li>Test API independently</li>\n<li>Review n8n workflow logs</li>\n</ol>\n<h2>üìö Additional Resources</h2>\n<ul>\n<li><a href=\"https://docs.n8n.io\">n8n Documentation</a></li>\n<li><a href=\"https://reactjs.org/docs\">React Documentation</a></li>\n<li><a href=\"https://www.typescriptlang.org/docs/\">TypeScript Documentation</a></li>\n<li><a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API\">Fetch API Guide</a></li>\n</ul>\n<h2>üÜò Need Help?</h2>\n<ul>\n<li>Check the <a href=\"https://community.n8n.io\">n8n Community Forum</a></li>\n<li>Review the troubleshooting guide</li>\n<li>Test your API connection</li>\n</ul>\n",
    "targetAudience": [
      "Developers",
      "AI Enthusiasts",
      "Website Owners"
    ]
  },
  {
    "id": 4,
    "title": "Understanding MCP (Model Context Protocol)",
    "summary": "A new term that's been gaining attention in the AI world is MCP ‚Äì Model Context Protocol. To understand MCP and its significance, let's first take a quick journey through the evolution of LLMs and how we interact with them today.",
    "date": "April 5, 2024",
    "imageUrl": "https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/MCP-Blog-Images/Title.png",
    "slug": "understanding-mcp",
    "tags": [
      "MCP",
      "Model Context Protocol",
      "LLMs",
      "RAG",
      "Tool Integration",
      "AI Development",
      "Automation",
      "API",
      "Zapier",
      "Cursor AI"
    ],
    "content": "<h1>Understanding MCP (Model Context Protocol)</h1>\n<h2>Introduction</h2>\n<p>A new term that&#39;s been gaining attention in the AI world is <strong>MCP</strong> ‚Äì <strong>Model Context Protocol</strong>. To understand MCP and its significance, let&#39;s first take a quick journey through the evolution of LLMs and how we interact with them today.</p>\n<h2>1. The First Evolution: LLMs (Large Language Models)</h2>\n<p>The first big revolution came with the introduction of <strong>LLMs</strong> ‚Äì large models trained on massive datasets, giving them what we can imagine as a &quot;big head full of past data&quot;. These models are excellent at understanding and generating human-like text.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/MCP-Blog-Images/First.png\" alt=\"An illustration showing the concept of a large model with vast past knowledge\"></p>\n<h2>2. RAG Models: Enhancing LLMs</h2>\n<p>Soon after, the concept of <strong>RAG</strong> ‚Äì <strong>Retrieval-Augmented Generation</strong> ‚Äì was introduced.<br>RAG means the model first <strong>retrieves</strong> relevant information from an external source, and then <strong>generates</strong> a response based on that, converting it into natural human language.</p>\n<p>This was a game-changer. Companies began feeding LLMs with their own data using RAG pipelines, allowing for dynamic and relevant responses.</p>\n<h2>3. The Tooling Era: Connecting LLMs with Real-World Tools</h2>\n<p>As OpenAI and other big players emerged, the next step was <strong>tool integration</strong>.<br>LLMs, by themselves, cannot take actions like reading emails or searching the web. So we started giving them <strong>tools</strong>.</p>\n<p>A great example is the <strong>web search tool</strong> in ChatGPT ‚Äì it allows the LLM to research current data. Then came platforms like <strong>n8n</strong>, <strong>Make</strong>, and <strong>Zapier</strong>, which enabled integration with 500+ apps.</p>\n<p>However, there were two major limitations for non-technical users:</p>\n<ol>\n<li><p><strong>Manual Node Configuration</strong>: Each step or &quot;node&quot; in a workflow needs to be manually described.</p>\n</li>\n<li><p><strong>Lack of Adaptability</strong>: If the task changes, the workflow is often not reusable.</p>\n</li>\n</ol>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/MCP-Blog-Images/Second.jpeg\" alt=\"A workflow showing manual configuration in n8n\"></p>\n<h2>4. Enter MCP: The Missing Link</h2>\n<p>This is where <strong>MCP (Model Context Protocol)</strong> comes in.</p>\n<p>MCP acts as a <strong>broker between LLMs and tools</strong>, making it easier for the model to know <strong>what to do</strong> and <strong>how to do it</strong>, <strong>without you needing to explicitly define every detail</strong>.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/MCP-Blog-Images/Third.png\" alt=\"Architecture of MCP: Tools at the bottom, MCP Server in the middle, and MCP Clients on top\"><br>(Source: <a href=\"https://norahsakal.com/blog/mcp-vs-api-model-context-protocol-explained/\">Norah Sakal&#39;s Blog on MCP</a>)</p>\n<h3>Before MCP:</h3>\n<blockquote>\n<p>If you asked an LLM: &quot;Get me the latest emails,&quot;<br>‚ùå It wouldn&#39;t know how ‚Äì it has no access to your Gmail or database.</p>\n</blockquote>\n<h3>After MCP:</h3>\n<blockquote>\n<p>You ask: &quot;Get me the latest emails.&quot;<br>‚úÖ The MCP server routes this request to the right tool (like Gmail), retrieves the data, and the LLM uses that to respond.<br>And <strong>you</strong>, the client, remain in full control.</p>\n</blockquote>\n<p>This architecture enables tool makers like GitHub, Google, etc., to build <strong>MCP-compatible integrations</strong>, making things seamless.</p>\n<h2>5. Hands-On Example: Building Your MCP Workflow</h2>\n<p>Let&#39;s build a simple <strong>MCP server</strong> using <strong>Cursor AI</strong> and <strong>Zapier MCP</strong>.</p>\n<ol>\n<li><p>Go to the <a href=\"https://actions.zapier.com/\">Zapier Actions Site</a> and follow the documentation.</p>\n</li>\n<li><p>Create an MCP project and connect it with Cursor AI.</p>\n</li>\n<li><p>In your Cursor settings, you&#39;ll see your connected MCP (like the image below).</p>\n</li>\n</ol>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/MCP-Blog-Images/Fourth.jpeg\" alt=\"Zapier MCP connected to Cursor\"></p>\n<h2>6. Adding Actions via Zapier</h2>\n<p>Next, you can start adding <strong>actions</strong>. For example, connect your Gmail.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/MCP-Blog-Images/Fifth.jpeg\" alt=\"Gmail added as an action in Zapier\"></p>\n<p>Now, inside any Cursor project, you can use natural language like:</p>\n<blockquote>\n<p>&quot;Send an email to John with this message.&quot;</p>\n</blockquote>\n<p>And it will send the email using the pre-defined action.</p>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/MCP-Blog-Images/Sixth.jpeg\" alt=\"A test example in Cursor where an email was sent just by using natural language\"></p>\n<h2>7. Final Output</h2>\n<p><img src=\"https://sanath-blog-public-images.s3.eu-north-1.amazonaws.com/images/MCP-Blog-Images/Seventh.jpeg\" alt=\"Screenshot of the email received as a meeting reminder ‚Äì triggered by MCP through Cursor\"></p>\n<h2>Conclusion</h2>\n<p>MCP is still in its <strong>early stages</strong>, but it has the potential to transform how we interact with AI and tools. Instead of coding or manually describing workflows, we can now just talk to our AI agent ‚Äî and it will <strong>understand, retrieve, and act</strong>.</p>\n<p>We believe that in the coming years, companies across the globe will embrace MCP to offer seamless integration between their APIs and AI interfaces.</p>\n",
    "targetAudience": [
      "Developers",
      "AI Enthusiasts",
      "Technical Writers",
      "Integration Specialists"
    ]
  }
]